{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tf\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import splitfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collecting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset diambil dari website kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tujuan PA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Membuat sebuah model yang dapat mengenali jenis dari serangga dengan menggunakan algoritma CNN.\n",
        "\n",
        "Batasan:\n",
        "  - Model ini hanya dapat mengenali:\n",
        "    - Kupu - Kupu, \n",
        "    - Capung, \n",
        "    - Nyamuk, \n",
        "    - Belalang,\n",
        "    - dan Kumbang."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deskripsi Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset ini berupa gambar dari 5 serangga berbeda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCbLiD-z4_Sr"
      },
      "source": [
        "### Jumlah Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Kupu - Kupu: 899\n",
        "- Capung: 1036\n",
        "- Nyamuk: 690\n",
        "- Belalang: 960\n",
        "- Kumbang: 864\n",
        "\n",
        "Total: 4449 data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTRd7_gQ0jme"
      },
      "source": [
        "### Data Train & Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLnJ95AqASza"
      },
      "source": [
        "URL path ke direktori dataset.\n",
        "berupa direktori dataset.\n",
        "dan dataset output (dataset yang akan dihasilkan ketika melakukan split folder). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tTakvVRPAIUX"
      },
      "outputs": [],
      "source": [
        "url = 'dataset_serangga'\n",
        "url_split = 'dataset-output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrzKKJuE-J6j",
        "outputId": "b69c6652-1914-451c-f96b-1199078cfba3"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio(url, output=url_split, seed=42, ratio=(0.7,0.2,0.1), group_prefix=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-voTqnW12yF"
      },
      "source": [
        "Disini saya menggunakan Image data generator dan batch size sebanyak 128\n",
        "untuk validation, saya menggunakan 20% data.\n",
        "Kemudian untuk subset training dan validation, target size nya adalah 120."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRnQIfrTAXHr"
      },
      "source": [
        "ambil path dari folder masing - masing output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5dwojDaYAMGq"
      },
      "outputs": [],
      "source": [
        "train = 'dataset-output/train'\n",
        "val = 'dataset-output/val'\n",
        "test = 'dataset-output/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq3Pe7fLJyn-",
        "outputId": "7e7bee6d-ab0c-433c-f993-db2abf797e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3112 images belonging to 5 classes.\n",
            "Found 449 images belonging to 5 classes.\n",
            "Found 888 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=45,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train = train_image_generator.flow_from_directory(\n",
        "    train, \n",
        "    target_size=(120,120),\n",
        "    batch_size=batch_size, \n",
        ")\n",
        "\n",
        "test = train_image_generator.flow_from_directory(\n",
        "    test, \n",
        "    target_size=(120,120),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val = train_image_generator.flow_from_directory(\n",
        "    val, \n",
        "    target_size=(120,120),\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDD9wZz0Jhx"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30_h3xrC0U_Q"
      },
      "source": [
        "Pada syntax di atas model dibentuk dengan suatu layer convo 2 dimensi dari size 120 x 120 pixels dimana fungsi aktivasinya adalah. Terdapat dua pembuatan layer convo, sehingga dilanjutkan dengan pembuatan layer max pooling dan pembuatan layer dropout. Karena ini adalah pelatihan deep learning maka perlu pelatihan lagi dengan membuat lagi layer untuk pelatihan. Kemudian dilanjutkan dengan layer flatten dan layer dense sampai dengan proses kompilasi.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KKASX8IMKDe5"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(\n",
        "        64, \n",
        "        (3,3), \n",
        "        activation='relu',\n",
        "        input_shape=(120, 120, 3), \n",
        "        padding='same'\n",
        "        ),\n",
        "\n",
        "      tf.keras.layers.Conv2D(\n",
        "        64, (3,3), \n",
        "        activation='relu',\n",
        "        input_shape=(120, 120, 3),\n",
        "        padding='same'\n",
        "        ),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        256, \n",
        "        (3,3), \n",
        "        activation='relu', \n",
        "        padding='same'\n",
        "        ),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(\n",
        "      256, \n",
        "      (3,3), \n",
        "      activation='relu',\n",
        "      padding='same'\n",
        "      ),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    \n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')     \n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQhZ89wtL9Hf",
        "outputId": "ab48b645-009b-41c5-e82a-3ad85ef9f68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 120, 120, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 120, 120, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 60, 60, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60, 60, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 256)       147712    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 60, 60, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30, 30, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 230400)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               29491328  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,268,485\n",
            "Trainable params: 30,268,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qUlStieAL-IA"
      },
      "outputs": [],
      "source": [
        "steps, val_steps = train.n/batch_size, val.n/batch_size\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_epCVuzj1v5h"
      },
      "source": [
        "epoch dibuat sebanyak 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xlfQiSR6-wG7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 1337s 51s/step - loss: 1.9946 - accuracy: 0.2629 - val_loss: 1.4878 - val_accuracy: 0.3761\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 1411s 59s/step - loss: 1.4717 - accuracy: 0.3406 - val_loss: 1.4354 - val_accuracy: 0.3694\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 1174s 48s/step - loss: 1.3955 - accuracy: 0.3904 - val_loss: 1.3527 - val_accuracy: 0.3851\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 1104s 45s/step - loss: 1.3601 - accuracy: 0.4145 - val_loss: 1.2998 - val_accuracy: 0.4955\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 993s 41s/step - loss: 1.3063 - accuracy: 0.4534 - val_loss: 1.2159 - val_accuracy: 0.5146\n",
            "Epoch 6/50\n",
            "24/24 [============================>.] - ETA: 16s - loss: 1.2451 - accuracy: 0.4953 "
          ]
        }
      ],
      "source": [
        "history = model.fit(train, validation_data=val, epochs=num_epochs,\n",
        "                    steps_per_epoch=steps, validation_steps=val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fegm8ZkG-xUT"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Akurasi Training')\n",
        "plt.plot(epochs, val_acc, 'g', label='Akurasi Validation')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Akurasi')\n",
        "plt.title('Akurasi Training and validation')\n",
        "plt.grid(axis='both')\n",
        "\n",
        "plt.show() "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
